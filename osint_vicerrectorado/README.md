# Sistema OSINT - Vicerrectorado EMI Bolivia

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Status-Sprint%201--2-orange.svg)

Sistema de recolecciÃ³n y anÃ¡lisis de datos de fuentes abiertas (OSINT) para el Vicerrectorado de la Escuela Militar de IngenierÃ­a (EMI) Bolivia.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un sistema automatizado de Open Source Intelligence (OSINT) que:

- **Recolecta** datos pÃºblicos de redes sociales (Facebook y TikTok)
- **Procesa** los datos mediante un pipeline ETL (Extract, Transform, Load)
- **Almacena** la informaciÃ³n en una base de datos SQLite estructurada
- **Automatiza** la recolecciÃ³n periÃ³dica mediante un scheduler

### Objetivo EspecÃ­fico 1
> "Analizar datos provenientes de fuentes abiertas, utilizando tÃ©cnicas de Open Source Intelligence (OSINT) para construir una base de datos de la informaciÃ³n"

## ğŸ¯ Fuentes de Datos Configuradas

| Plataforma | Cuenta | URL |
|------------|--------|-----|
| Facebook | EMI Oficial | https://www.facebook.com/profile.php?id=61574626396439 |
| Facebook | EMI UALP | https://www.facebook.com/EMI.UALP |
| TikTok | EMI La Paz Oficial | https://www.tiktok.com/@emilapazoficial |

## ğŸš€ InstalaciÃ³n

### Prerrequisitos

- Python 3.10 o superior
- pip (gestor de paquetes de Python)
- Git

### Pasos de InstalaciÃ³n

1. **Clonar el repositorio**
```bash
cd SISTEMA_ANALÃTICA_EMI
cd osint_vicerrectorado
```

2. **Crear entorno virtual**
```bash
python -m venv venv
source venv/bin/activate  # En macOS/Linux
# o
venv\Scripts\activate  # En Windows
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Instalar Playwright**
```bash
playwright install chromium
```

5. **Inicializar base de datos**
```bash
python main.py --init-db
```

## ğŸ“– Uso

### Comandos Principales

| Comando | DescripciÃ³n |
|---------|-------------|
| `--collect` | Ejecutar recolecciÃ³n de datos OSINT |
| `--process` | Ejecutar procesamiento ETL |
| `--stats` | Mostrar estadÃ­sticas del sistema |
| `--schedule-start` | Iniciar scheduler automÃ¡tico |
| `--init-db` | Inicializar base de datos |
| `--export` | Exportar datos a CSV |

### Ejemplos

**RecolecciÃ³n manual de todas las fuentes:**
```bash
python main.py --collect
```

**RecolecciÃ³n con lÃ­mite especÃ­fico:**
```bash
python main.py --collect --limit 50
```

**RecolecciÃ³n solo de Facebook:**
```bash
python main.py --collect --source facebook
```

**Ejecutar procesamiento ETL:**
```bash
python main.py --process
```

**Ver estadÃ­sticas:**
```bash
python main.py --stats
```

**Iniciar scheduler automÃ¡tico (12 horas):**
```bash
python main.py --schedule-start
```

**Exportar datos procesados:**
```bash
python main.py --export --output datos_osint.csv
```

## ğŸ“ Estructura del Proyecto

```
osint_vicerrectorado/
â”œâ”€â”€ main.py                 # CLI principal
â”œâ”€â”€ config.json             # ConfiguraciÃ³n del sistema
â”œâ”€â”€ requirements.txt        # Dependencias Python
â”œâ”€â”€ README.md               # Este archivo
â”‚
â”œâ”€â”€ scrapers/               # MÃ³dulos de scraping
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_scraper.py     # Clase base con Template Method
â”‚   â”œâ”€â”€ facebook_scraper.py # Scraper de Facebook
â”‚   â””â”€â”€ tiktok_scraper.py   # Scraper de TikTok
â”‚
â”œâ”€â”€ database/               # MÃ³dulo de base de datos
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ schema.sql          # Esquema SQLite
â”‚   â””â”€â”€ db_writer.py        # Gestor de base de datos
â”‚
â”œâ”€â”€ etl/                    # MÃ³dulos ETL
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_cleaner.py     # Limpieza de datos
â”‚   â”œâ”€â”€ data_transformer.py # TransformaciÃ³n de datos
â”‚   â”œâ”€â”€ data_validator.py   # ValidaciÃ³n de datos
â”‚   â””â”€â”€ etl_controller.py   # Controlador del pipeline
â”‚
â”œâ”€â”€ controllers/            # Controladores principales
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ osint_controller.py # Orquestador de scrapers
â”‚
â”œâ”€â”€ utils/                  # Utilidades
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ rate_limiter.py     # Control de tasa de peticiones
â”‚   â””â”€â”€ logger.py           # ConfiguraciÃ³n de logging
â”‚
â”œâ”€â”€ tests/                  # Tests unitarios
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py         # ConfiguraciÃ³n de pytest
â”‚   â”œâ”€â”€ test_scrapers.py    # Tests de scrapers
â”‚   â”œâ”€â”€ test_etl.py         # Tests de ETL
â”‚   â”œâ”€â”€ test_database.py    # Tests de base de datos
â”‚   â””â”€â”€ test_controller.py  # Tests del controlador
â”‚
â””â”€â”€ data/                   # Datos y logs (gitignored)
    â”œâ”€â”€ osint_emi.db        # Base de datos SQLite
    â””â”€â”€ logs/               # Archivos de log
```

## ğŸ—„ï¸ Esquema de Base de Datos

### Tablas Principales

#### `fuente_osint`
Almacena informaciÃ³n de las fuentes de datos configuradas.

| Campo | Tipo | DescripciÃ³n |
|-------|------|-------------|
| id | INTEGER | ID primario |
| nombre | TEXT | Nombre descriptivo |
| tipo | TEXT | Facebook, TikTok, etc. |
| url | TEXT | URL de la fuente |
| identificador | TEXT | ID Ãºnico de la plataforma |
| activo | INTEGER | Estado activo/inactivo |

#### `dato_recolectado`
Almacena los datos raw recolectados de las fuentes.

| Campo | Tipo | DescripciÃ³n |
|-------|------|-------------|
| id | INTEGER | ID primario |
| id_fuente | INTEGER | FK a fuente_osint |
| id_externo | TEXT | ID del post en la plataforma |
| contenido | TEXT | Texto del post |
| fecha_publicacion | DATETIME | Fecha de publicaciÃ³n |
| likes | INTEGER | NÃºmero de likes |
| comentarios | INTEGER | NÃºmero de comentarios |
| compartidos | INTEGER | NÃºmero de compartidos |
| tipo_contenido | TEXT | post, video, etc. |
| metadata | TEXT | JSON con datos adicionales |

#### `dato_procesado`
Almacena los datos despuÃ©s del procesamiento ETL.

| Campo | Tipo | DescripciÃ³n |
|-------|------|-------------|
| id | INTEGER | ID primario |
| id_dato_raw | INTEGER | FK a dato_recolectado |
| contenido_limpio | TEXT | Texto procesado |
| sentimiento | TEXT | positive, negative, neutral |
| categoria | TEXT | ClasificaciÃ³n del contenido |
| semestre_academico | TEXT | PerÃ­odo acadÃ©mico |
| engagement_score | REAL | Score normalizado |

#### `log_ejecucion`
Registra las ejecuciones del sistema.

| Campo | Tipo | DescripciÃ³n |
|-------|------|-------------|
| id | INTEGER | ID primario |
| tipo | TEXT | recoleccion, etl |
| fuente | TEXT | Fuente procesada |
| inicio | DATETIME | Hora de inicio |
| fin | DATETIME | Hora de fin |
| exito | INTEGER | Estado de Ã©xito |
| procesados | INTEGER | Total procesados |

## ğŸ§ª Tests

### Ejecutar todos los tests
```bash
pytest tests/ -v
```

### Ejecutar con cobertura
```bash
pytest tests/ -v --cov=. --cov-report=html
```

### Ejecutar tests especÃ­ficos
```bash
# Solo scrapers
pytest tests/test_scrapers.py -v

# Solo ETL
pytest tests/test_etl.py -v

# Solo database
pytest tests/test_database.py -v
```

### Cobertura Objetivo
- **MÃ­nimo**: 85% en mÃ³dulos core
- **Tests**: 15+ tests unitarios

## âš™ï¸ ConfiguraciÃ³n

El archivo `config.json` contiene toda la configuraciÃ³n del sistema:

```json
{
  "database": {
    "path": "data/osint_emi.db",
    "type": "sqlite"
  },
  "sources": {
    "facebook": {
      "enabled": true,
      "pages": [...]
    },
    "tiktok": {
      "enabled": true,
      "accounts": [...]
    }
  },
  "scraping": {
    "min_delay_seconds": 3,
    "max_delay_seconds": 7,
    "max_retries": 3
  },
  "scheduler": {
    "collection_interval_hours": 12,
    "etl_interval_hours": 6
  }
}
```

## ğŸ”’ TÃ©cnicas Anti-DetecciÃ³n

El sistema implementa varias tÃ©cnicas para evitar bloqueos:

1. **RotaciÃ³n de User-Agents**: 15+ user agents diferentes
2. **Delays aleatorios**: 3-7 segundos entre peticiones
3. **Rate limiting**: LÃ­mites por plataforma (60 req/h Facebook, 30 req/h TikTok)
4. **Navegador headless**: Chromium con configuraciÃ³n stealth
5. **Viewport realista**: 1920x1080 (desktop) o mÃ³vil para TikTok

## ğŸ“Š Pipeline ETL

### 1. ExtracciÃ³n (Extract)
- Lectura de datos no procesados de `dato_recolectado`
- ConversiÃ³n a DataFrame de pandas

### 2. Limpieza (Clean)
- EliminaciÃ³n de URLs
- NormalizaciÃ³n de espacios
- CorrecciÃ³n de encoding UTF-8
- Opcional: eliminaciÃ³n de emojis, menciones, hashtags

### 3. TransformaciÃ³n (Transform)
- ExtracciÃ³n de caracterÃ­sticas temporales (dÃ­a, hora, semestre acadÃ©mico)
- NormalizaciÃ³n de engagement (0-100)
- ClasificaciÃ³n de contenido (FelicitaciÃ³n, Queja, Sugerencia, etc.)
- AnÃ¡lisis de sentimiento bÃ¡sico

### 4. ValidaciÃ³n (Validate)
- VerificaciÃ³n de campos requeridos
- ValidaciÃ³n de rangos numÃ©ricos
- Filtrado de registros invÃ¡lidos

### 5. Carga (Load)
- Guardado en `dato_procesado`
- Marcado de registros raw como procesados
- Registro de ejecuciÃ³n en logs

## ğŸ“ˆ MetodologÃ­a Scrum

### Sprint 1: MÃ³dulo de RecolecciÃ³n Automatizada
- [x] ConfiguraciÃ³n de fuentes
- [x] Scrapers para Facebook y TikTok
- [x] Almacenamiento en base de datos
- [x] Scheduler para automatizaciÃ³n

### Sprint 2: Pipeline ETL
- [x] Limpieza de datos
- [x] TransformaciÃ³n y enriquecimiento
- [x] ValidaciÃ³n de datos
- [x] Tests unitarios (15+)

## ğŸ› ï¸ TecnologÃ­as Utilizadas

| CategorÃ­a | TecnologÃ­a |
|-----------|------------|
| Lenguaje | Python 3.10+ |
| Web Scraping | Playwright, BeautifulSoup4 |
| Base de Datos | SQLite |
| ETL | pandas, numpy |
| Scheduler | APScheduler |
| Testing | pytest, pytest-cov |
| Logging | logging (Python stdlib) |

## ğŸ“ Notas Importantes

1. **Datos Reales**: Este sistema recolecta datos reales de fuentes pÃºblicas. No se utilizan datos simulados.

2. **Uso Responsable**: Respetar los tÃ©rminos de servicio de las plataformas y las leyes de protecciÃ³n de datos.

3. **Rate Limiting**: Los lÃ­mites de tasa estÃ¡n configurados para evitar sobrecarga en los servidores.

4. **Logs**: Todos los logs se almacenan en `data/logs/` para auditorÃ­a.

## ğŸ“„ Licencia

Este proyecto es para uso acadÃ©mico de la Escuela Militar de IngenierÃ­a (EMI) Bolivia.

## ğŸ‘¥ Autor

Sistema desarrollado para el Vicerrectorado EMI como parte del proyecto de analÃ­tica de datos.

---

**VersiÃ³n**: 1.0.0  
**Ãšltima actualizaciÃ³n**: Diciembre 2024
